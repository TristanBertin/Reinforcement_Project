{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i ] CrÃ©ation de l'environnement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](representation_envi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll use the OpenAI Gym framework to build our environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "from gym.envs.toy_text import discrete\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "class AugmentedGridworldEnv(discrete.DiscreteEnv):\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "    \n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.shape = (10, 20)\n",
    "        self.nS = np.prod(self.shape)\n",
    "        self.nA = 4\n",
    "        \n",
    "        # Cliff Location\n",
    "        self._cliff = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._cliff[0, 11:15] = True; self._cliff[1, 10:13] = True\n",
    "        self._cliff[9, 3:7] = True; self._cliff[8, 3:5] = True; self._cliff[7, 4:7] = True; self._cliff[6, 5:7] = True\n",
    "        self._cliff[3, 18] = True; self._cliff[4, 17:20] = True; self._cliff[8, 14] = True; self._cliff[9, 16:18] = True\n",
    "        \n",
    "        #Big cheese location\n",
    "        self._cheese = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._cheese[7,17] = True; self._cheese[9,2] = True\n",
    "        \n",
    "        #Carrots initial location\n",
    "        self._ini_carrots= np.zeros(self.shape, dtype=np.bool)\n",
    "        self._ini_carrots[2, 4] = True\n",
    "        self._ini_carrots[5, 2] = True; self._ini_carrots[1, 8] = True\n",
    "        self._ini_carrots[8, 10] = True; self._ini_carrots[7, 11] = True\n",
    "        self._ini_carrots[1, 13:15] = True; self._ini_carrots[0:4, 19] = True\n",
    "        \n",
    "        self._carrots = np.copy(self._ini_carrots)\n",
    "\n",
    "        # Wind location and strenghts\n",
    "        self._winds = np.zeros(self.shape)\n",
    "        self._winds[7:9 ,0:3] = 1; self._winds[6,3] = 1\n",
    "        self._winds[1,9] = 1\n",
    "        self._winds[3,15:18] = 1; self._winds[4,14] = 1\n",
    "        \n",
    "        # Walls Location\n",
    "        self._walls = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._walls[0:4,5] = True \n",
    "        self._walls[4,10:13] = True \n",
    "        self._walls[5:9,13] = True\n",
    "        \n",
    "        # We always start in state (0, 0)\n",
    "        self.ini_state = np.ravel_multi_index((0,0), self.shape)\n",
    "        isd = np.zeros(self.nS)\n",
    "        isd[self.ini_state] = 1.0\n",
    "                                \n",
    "        # Calculate transition probabilities\n",
    "        self.P = {}\n",
    "        self._actualize_transition_probabilities()\n",
    "\n",
    "        super(AugmentedGridworldEnv, self).__init__(self.nS, self.nA, self.P, isd)\n",
    "        \n",
    "        \n",
    "    def _actualize_transition_probabilities(self): #once we have eaten the carrot, we have to compute again those probabilities\n",
    "        \n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape) #gives the couple (x,y) from the indice of the state (ex:18 -> (2,8))\n",
    "    \n",
    "            self.P[s] = { a : [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "        \n",
    "    def _limit_coordinates(self, coord): #To be sure that we are in the admissible states\n",
    "        coord[0] = min(coord[0], self.shape[0] - 1) #for right-overtaking\n",
    "        coord[0] = max(coord[0], 0) #for left overtaking\n",
    "        coord[1] = min(coord[1], self.shape[1] - 1)  #for botom overtaking\n",
    "        coord[1] = max(coord[1], 0) # for up overtaking\n",
    "        return coord\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        \n",
    "        new_position = np.array(current) + np.array(delta) + np.array([0, 1]) * self._winds[tuple(current)] #[0,1] because wind push you to right\n",
    "        new_position = self._limit_coordinates(new_position).astype(int) #to be sure that we stay in the frame\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape) #from coordinates couple to flat index\n",
    "        \n",
    "        proba = 1.0 #no noise on dispalcements\n",
    "        \n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            reward = -100.0\n",
    "        elif self._cheese[tuple(new_position)]:\n",
    "            reward = +50.0 \n",
    "        elif self._carrots[tuple(new_position)]: #+10 for a carrot\n",
    "            reward = +10.0 \n",
    "        elif self._walls[tuple(new_position)]: # if new state is a wall, probability = 0\n",
    "            proba = 0; reward = 0\n",
    "        else: # no element on this state\n",
    "            reward = -1 #-1 for a classic displacement\n",
    "        \n",
    "        is_done = self._cliff[tuple(new_position)] or self._cheese[tuple(new_position)] #end if cliffs or big cheese\n",
    "        \n",
    "        return [(proba, new_state, reward, is_done)]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        state, reward, done, proba = super().step(action) #we overwrite the method of the global env (with super().)\n",
    "        position = np.unravel_index(state, self.shape)\n",
    "\n",
    "        if self._carrots[tuple(position)]: #we remove the carrot if we get it\n",
    "            self._carrots[tuple(position)] = False\n",
    "            self._actualize_transition_probabilities()\n",
    "        \n",
    "        return state, reward, done, proba\n",
    "    \n",
    "    def reset(self,):\n",
    "        super().reset()\n",
    "        self._carrots = np.copy(self._ini_carrots)\n",
    "        self._actualize_transition_probabilities()\n",
    "        return self.ini_state\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False): #public method\n",
    "        self._render(mode, close)\n",
    "\n",
    "    def _render(self, mode='human', close=False): # private method\n",
    "        \n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            \n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            \n",
    "            if self.s == s:\n",
    "                output = u\"\\U0001F42D\"\n",
    "            elif self._cliff[position]:  #tuple\n",
    "                output = u\"\\U0001F30A\"\n",
    "            elif self._cheese[position]:\n",
    "                output = u\"\\U0001F9C0\"\n",
    "            elif self._carrots[position]: #+10 for a small cheese\n",
    "                output = u\"\\U0001F955\"\n",
    "            elif self._walls[position]: # if new state is a wall, probability = 0, else = 1 (no noisy movements)\n",
    "                output = u\"\\u2588\"\n",
    "            elif self._winds[position]: # if new state is a wall, probability = 0, else = 1 (no noisy movements)\n",
    "                output = u\"\\u21D2\"\n",
    "            else:\n",
    "                output = \" \" + u\"\\u25CB\"\n",
    "\n",
    "            if position[1] == 0:\n",
    "                output = output.lstrip()\n",
    "            if position[1] == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                output += \"\\n\"\n",
    "\n",
    "            outfile.write(output)\n",
    "            \n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "    def render_policy(self, reshaped_policy, close=False): \n",
    "        \n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = sys.stdout\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            \n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            \n",
    "            if reshaped_policy[position] == 0:\n",
    "                output = u\"\\u2191\"\n",
    "            elif reshaped_policy[position] == 1:\n",
    "                output = u\"\\u2192\"\n",
    "            elif reshaped_policy[position] == 2:\n",
    "                output = u\"\\u2193\"\n",
    "            elif reshaped_policy[position] == 3:\n",
    "                output = u\"\\u2190\"\n",
    "\n",
    "            if position[1] == 0:\n",
    "                output = output.lstrip()\n",
    "            if position[1] == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                output += \"\\n\"\n",
    "\n",
    "            outfile.write(output)\n",
    "            \n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "    def render_trajectory(self, states_trajectory, rewards_trajectory=None):\n",
    "        \n",
    "        self.reset()\n",
    "        self.reward_matrix = np.zeros(self.shape)\n",
    "        self.reward_matrix[self._cliff] = -100\n",
    "        self.reward_matrix[self._carrots] = 10\n",
    "        self.reward_matrix[self._cheese] = 50\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        \n",
    "        if rewards_trajectory != None:\n",
    "            plt.subplot(121)\n",
    "\n",
    "        plt.imshow(self.reward_matrix, 'jet')\n",
    "        c = cm.OrRd(np.linspace(0, 1, len(states_trajectory)))\n",
    "        plt.scatter(np.unravel_index(states_trajectory, self.shape)[1], np.unravel_index(states_trajectory, self.shape)[0], color=c)\n",
    "        \n",
    "        if rewards_trajectory != None:\n",
    "            plt.subplot(122)\n",
    "            plt.plot(np.array(rewards_trajectory))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AugmentedGridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
