{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i ] CrÃ©ation de l'environnement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](representation_envi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll use the OpenAI Gym framework to build our environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "from gym.envs.toy_text import discrete\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "class AugmentedGridworldEnv(discrete.DiscreteEnv):\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "    \n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.shape = (10, 20)\n",
    "        self.nS = np.prod(self.shape)\n",
    "        self.nA = 4\n",
    "        \n",
    "        # Cliff Location\n",
    "        self._cliff = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._cliff[0, 12:15] = True; self._cliff[1, 10:13] = True\n",
    "        self._cliff[9, 3] = True; self._cliff[9, 5:7] = True; self._cliff[8, 3:4] = True; self._cliff[7, 4:7] = True; self._cliff[6, 5:7] = True\n",
    "        self._cliff[3, 18] = True; self._cliff[4, 17:20] = True; self._cliff[8, 14] = True; self._cliff[9, 16:18] = True\n",
    "        \n",
    "        #Big cheese location\n",
    "        self._cheese = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._cheese[7,17] = True\n",
    "        #self._cheese[7,16] = True;\n",
    "        self._cheese[9,2] = True\n",
    "        \n",
    "        #Carrots initial location\n",
    "        self._ini_carrots= np.zeros(self.shape, dtype=np.bool)\n",
    "        self._ini_carrots[2, 4] = True\n",
    "        self._ini_carrots[5, 2] = True; self._ini_carrots[1, 8] = True\n",
    "        self._ini_carrots[8, 10] = True; self._ini_carrots[7, 11] = True\n",
    "        self._ini_carrots[1, 13:14] = True; self._ini_carrots[1, 18] = True\n",
    "        \n",
    "        self._carrots = np.copy(self._ini_carrots)\n",
    "\n",
    "        # Wind location and strenghts\n",
    "        self._winds = np.zeros(self.shape)\n",
    "        self._winds[7:9 ,0:3] = 1; self._winds[6,3] = 1\n",
    "        self._winds[1,9] = 1\n",
    "        self._winds[3,15:18] = 1; self._winds[4,14] = 1\n",
    "        \n",
    "        # Walls Location\n",
    "        self._walls = np.zeros(self.shape, dtype=np.bool)\n",
    "        self._walls[0:4,5] = True \n",
    "        self._walls[4,10:13] = True \n",
    "        self._walls[5:9,13] = True\n",
    "        \n",
    "        # We always start in state (0, 0)\n",
    "        self.ini_state = np.ravel_multi_index((0,0), self.shape)\n",
    "        isd = np.zeros(self.nS)\n",
    "        isd[self.ini_state] = 1.0\n",
    "                                \n",
    "        # Calculate transition probabilities\n",
    "        self.P = {}\n",
    "        self._actualize_transition_probabilities()\n",
    "\n",
    "        super(AugmentedGridworldEnv, self).__init__(self.nS, self.nA, self.P, isd)\n",
    "        \n",
    "        \n",
    "    def _actualize_transition_probabilities(self): #once we have eaten the carrot, we have to compute again those probabilities\n",
    "        \n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape) #gives the couple (x,y) from the indice of the state (ex:18 -> (2,8))\n",
    "    \n",
    "            self.P[s] = { a : [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "        \n",
    "    def _limit_coordinates(self, coord): #To be sure that we are in the admissible states\n",
    "        coord[0] = min(coord[0], self.shape[0] - 1) #for right-overtaking\n",
    "        coord[0] = max(coord[0], 0) #for left overtaking\n",
    "        coord[1] = min(coord[1], self.shape[1] - 1)  #for botom overtaking\n",
    "        coord[1] = max(coord[1], 0) # for up overtaking\n",
    "        return coord\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        \n",
    "        new_position = np.array(current) + np.array(delta) + np.array([0, 1]) * self._winds[tuple(current)] #[0,1] because wind push you to right\n",
    "        new_position = self._limit_coordinates(new_position).astype(int) #to be sure that we stay in the frame\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape) #from coordinates couple to flat index\n",
    "        \n",
    "        proba = 1.0 #no noise on dispalcements\n",
    "        \n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            reward = -100.0\n",
    "        elif self._cheese[tuple(new_position)]:\n",
    "            reward = +50.0 \n",
    "        elif self._carrots[tuple(new_position)]: #+3 for a carrot\n",
    "            reward = +3.0\n",
    "        elif self._walls[tuple(new_position)]: # if new state is a wall, probability = 0\n",
    "            proba = 0; reward = 0\n",
    "        else: # no element on this state\n",
    "            reward = -1 #-1 for a classic displacement\n",
    "        \n",
    "        is_done = self._cliff[tuple(new_position)] or self._cheese[tuple(new_position)] #end if cliffs or big cheese\n",
    "        \n",
    "        return [(proba, new_state, reward, is_done)]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        state, reward, done, proba = super().step(action) #we overwrite the method of the global env (with super().)\n",
    "        position = np.unravel_index(state, self.shape)\n",
    "\n",
    "        if self._carrots[tuple(position)]: #we remove the carrot if we get it\n",
    "            self._carrots[tuple(position)] = False\n",
    "            self._actualize_transition_probabilities()\n",
    "        \n",
    "        return state, reward, done, proba\n",
    "    \n",
    "    def reset(self,):\n",
    "        super().reset()\n",
    "        self._carrots = np.copy(self._ini_carrots)\n",
    "        self._actualize_transition_probabilities()\n",
    "        return self.ini_state\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False): #public method\n",
    "        self._render(mode, close)\n",
    "\n",
    "    def _render(self, mode='human', close=False): # private method\n",
    "        \n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            \n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            \n",
    "            if self.s == s:\n",
    "                output = u\"\\U0001F42D\"\n",
    "            elif self._cliff[position]:  #tuple\n",
    "                output = u\"\\U0001F30A\"\n",
    "            elif self._cheese[position]:\n",
    "                output = u\"\\U0001F9C0\"\n",
    "            elif self._carrots[position]: #+3 for a small cheese\n",
    "                output = u\"\\U0001F955\"\n",
    "            elif self._walls[position]: # if new state is a wall, probability = 0, else = 1 (no noisy movements)\n",
    "                output = u\"\\u2588\"\n",
    "            elif self._winds[position]: # if new state is a wall, probability = 0, else = 1 (no noisy movements)\n",
    "                output = u\"\\u21D2\"\n",
    "            else:\n",
    "                output = \" \" + u\"\\u25CB\"\n",
    "\n",
    "            if position[1] == 0:\n",
    "                output = output.lstrip()\n",
    "            if position[1] == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                output += \"\\n\"\n",
    "\n",
    "            outfile.write(output)\n",
    "            \n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "    def render_policy(self, reshaped_policy, close=False): \n",
    "        \n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = sys.stdout\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            \n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            \n",
    "            if reshaped_policy[position] == 0:\n",
    "                output = u\"\\u2191\"\n",
    "            elif reshaped_policy[position] == 1:\n",
    "                output = u\"\\u2192\"\n",
    "            elif reshaped_policy[position] == 2:\n",
    "                output = u\"\\u2193\"\n",
    "            elif reshaped_policy[position] == 3:\n",
    "                output = u\"\\u2190\"\n",
    "\n",
    "            if position[1] == 0:\n",
    "                output = output.lstrip()\n",
    "            if position[1] == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                output += \"\\n\"\n",
    "\n",
    "            outfile.write(output)\n",
    "            \n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "    \n",
    "    def render_trajectory(self, states_trajectory, rewards_trajectory=None):\n",
    "        \n",
    "        self.reset()\n",
    "        self.reward_matrix = np.zeros(self.shape)\n",
    "        self.reward_matrix[self._cliff] = -100\n",
    "        self.reward_matrix[self._carrots] = 3\n",
    "        self.reward_matrix[self._cheese] = 50\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        \n",
    "        if rewards_trajectory != None:\n",
    "            plt.subplot(121)\n",
    "\n",
    "        plt.imshow(self.reward_matrix, 'jet')\n",
    "        c = cm.OrRd(np.linspace(0, 1, len(states_trajectory)))\n",
    "        plt.scatter(np.unravel_index(states_trajectory, self.shape)[1], np.unravel_index(states_trajectory, self.shape)[0], color=c)\n",
    "        \n",
    "        if rewards_trajectory != None:\n",
    "            plt.subplot(122)\n",
    "            plt.plot(np.array(rewards_trajectory))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AugmentedGridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render_trajectory([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
